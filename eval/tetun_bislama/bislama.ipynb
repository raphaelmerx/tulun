{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import json\n",
    "from typing import List, Literal, Optional\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import os\n",
    "import random\n",
    "\n",
    "from gemini_aistudio import GenerativeModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from sacrebleu import corpus_chrf\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from translator_utils import Translator, Glossary, Line, LineManager, Message\n",
    "\n",
    "MODE: Literal[\"translate\", \"post-edit\"] = \"translate\"\n",
    "ZERO_SHOT: bool = True\n",
    "\n",
    "if MODE == \"post-edit\":\n",
    "    gemini = GenerativeModel(system_instruction=\"\"\"You are an expert translator. I am going to give you relevant glossary entries, and relevant past translations, where the first is the English source, the second is a machine translation of the English to Bislama, and the third is the Bislama reference translation. The sentences will be written English: <sentence> MT: <machine translated sentence> Bislama: <translated sentence>. After the example pairs, I am going to provide another sentence in English and its machine translation, and I want you to translate it into Bislama. Give only the translation, and no extra commentary, formatting, or chattiness. Translate the text from English to Bislama.\"\"\")\n",
    "elif MODE == \"translate\":\n",
    "    if ZERO_SHOT:\n",
    "        gemini = GenerativeModel(system_instruction=\"You are an expert translator. I am going to give you text in English, and would like you to translate it to Bislama. Give only the translation, and no extra commentary, formatting, or chattiness.\")\n",
    "    else:\n",
    "        gemini = GenerativeModel(system_instruction=\"\"\"You are an expert translator. I am going to give you some example pairs of text snippets where the first is in English and the second is a translation of the first snippet into Bislama. The sentences will be written English: <first sentence> Bislama: <translated first sentence> After the example pairs, I am going to provide another sentence in English and I want you to translate it into Bislama. Give only the translation, and no extra commentary, formatting, or chattiness. Translate the text from English to Bislama.\"\"\")\n",
    "\n",
    "TRANSLATE_WITH: Literal[\"google\", \"madlad\", \"opusmt\"] = \"madlad\"\n",
    "\n",
    "pred_key = f'tgt_pred_{TRANSLATE_WITH}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary = Glossary(file=\"datafiles/bislama_school_dictionary.json\")\n",
    "glossary.load_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select lines to translate\n",
    "\n",
    "with open('datafiles/bislama_parallel.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    lines: List[Line] = [Line(en=row['en'], tgt=row['tgt'], tgt_pred_madlad=row['tgt_pred_madlad'], tgt_pred_opusmt=row['tgt_pred_opusmt']) for row in reader]\n",
    "\n",
    "print(f\"Total of {len(lines)} lines\")\n",
    "\n",
    "lines = [l for l in lines if l.en and l.tgt]\n",
    "print(f\"Total of {len(lines)} lines with en and tgt\")\n",
    "\n",
    "\n",
    "mt_chrf = corpus_chrf(\n",
    "    [getattr(l, pred_key) for l in lines],\n",
    "    [[l.tgt for l in lines]],\n",
    "    word_order=2,\n",
    ")\n",
    "print(f\"CHRF for MT: {mt_chrf.score:.2f}\")\n",
    "\n",
    "random.seed(42)\n",
    "train_lines = lines[:int(len(lines) * 0.8)]\n",
    "print(f\"{len(train_lines)} lines for training\")\n",
    "test_lines = lines[int(len(lines) * 0.8):]\n",
    "print(f\"{len(test_lines)} lines for testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(translate_with=TRANSLATE_WITH)\n",
    "translator.init_bm25(train_lines)\n",
    "\n",
    "random.seed(42)\n",
    "train_sample = random.sample(train_lines, 10)\n",
    "\n",
    "def format_messages_for_gemini(messages: List[Message]) -> List[dict]:\n",
    "    return [{\n",
    "        \"role\": \"user\" if message.role == \"user\" else \"model\",\n",
    "        \"parts\": [message.content]\n",
    "    } for message in messages if message.role != 'system']\n",
    "\n",
    "def get_post_edited_translation_gemini(input_text: str) -> str:\n",
    "    # get glossary entries and similar sentences\n",
    "    glossary_entries = glossary.get_entries(input_text)\n",
    "    similar_sentences = translator.get_top_similar_sentences_bm25(input_text, top_n=10)\n",
    "\n",
    "    messages = translator.construct_prompt_post_edit(\n",
    "        input_text, \n",
    "        similar_sentences,\n",
    "        glossary_entries=glossary_entries,\n",
    "    )\n",
    "\n",
    "    # print(messages[0].content)\n",
    "    messages = format_messages_for_gemini(messages)\n",
    "\n",
    "    response = gemini.generate_content(\n",
    "        messages,\n",
    "    )\n",
    "    return response.strip()\n",
    "\n",
    "def get_final_translation_gemini(input_text: str) -> str:\n",
    "    messages = translator.construct_prompt_translation(\n",
    "        input_text,\n",
    "        train_sample if not ZERO_SHOT else [],\n",
    "    )\n",
    "\n",
    "    # print(messages[0].content)\n",
    "    messages = format_messages_for_gemini(messages)\n",
    "\n",
    "    response = gemini.generate_content(\n",
    "        messages,\n",
    "    )\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'src: {test_lines[1].en}')\n",
    "print(f'pred: {get_final_translation_gemini(test_lines[1].en)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "MAX_LINES = None\n",
    "\n",
    "\n",
    "if MODE == 'post-edit':\n",
    "    def process_line(line):\n",
    "        if not getattr(line, 'tgt_pred_post_edited', None):\n",
    "            line.tgt_pred_post_edited = get_post_edited_translation_gemini(line.en)\n",
    "        return line\n",
    "elif MODE == 'translate':\n",
    "    def process_line(line):\n",
    "        if not getattr(line, 'tgt_pred_gemini', None):\n",
    "            line.tgt_pred_gemini = get_final_translation_gemini(line.en)\n",
    "        return line\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    if MAX_LINES:\n",
    "        futures = [executor.submit(process_line, line) for line in test_lines[:MAX_LINES]]\n",
    "    else:\n",
    "        futures = [executor.submit(process_line, line) for line in test_lines]\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(test_lines)):\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrf_for_key(key: str):\n",
    "    chrf = corpus_chrf(\n",
    "        [getattr(l, key) for l in test_lines],\n",
    "        [[l.tgt for l in test_lines]],\n",
    "        word_order=2,\n",
    "    )\n",
    "    return chrf.score\n",
    "\n",
    "if MODE == 'post-edit':\n",
    "    mt_chrf = chrf_for_key(pred_key)\n",
    "    print(f\"CHRF for MT: {mt_chrf:.2f}\")\n",
    "\n",
    "    ape_chrf = chrf_for_key('tgt_pred_post_edited')\n",
    "    print(f\"CHRF for APE: {ape_chrf:.2f}\")\n",
    "elif MODE == 'translate':\n",
    "    gemini_chrf = chrf_for_key('tgt_pred_gemini')\n",
    "    print(f\"CHRF for Gemini: {gemini_chrf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for line in random.sample(test_lines, 5):\n",
    "    print(\"English:\", line.en)\n",
    "    stripped_bislama = strip_response_tags(line.tgt_pred_post_edited)\n",
    "    print(\"APE:\", stripped_bislama)\n",
    "    print(\"Reference:\", line.tgt)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('datafiles/bislama_parallel_gemini.csv', 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['en', 'tgt', 'tgt_pred_madlad', 'tgt_pred_post_edited'])\n",
    "    writer.writeheader()\n",
    "    for line in test_lines:\n",
    "        writer.writerow({\n",
    "            'en': line.en,\n",
    "            'tgt': line.tgt,\n",
    "            'tgt_pred_madlad': line.tgt_pred_madlad,\n",
    "            'tgt_pred_post_edited': line.tgt_pred_post_edited,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
